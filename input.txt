import asyncio
import aioredis
from collections import defaultdict

NUM_WORKERS = 5  # Change this for parallelism

async def process_trace(trace_id, messages):
    print(f"[LLM] Processing {trace_id} with {len(messages)} messages")
    await asyncio.sleep(1)  # Simulate LLM call
    print(f"[LLM] Done processing {trace_id}")

class TraceCollector:
    def __init__(self):
        self.traces = defaultdict(list)
        self.queue = asyncio.Queue()

    async def message_handler(self, msg):
        trace_id = msg.get("trace_id")
        event = msg.get("event")
        if event == "trace":
            self.traces[trace_id].append(msg)
        elif event == "trace_end":
            collected = self.traces.pop(trace_id, [])
            if collected:
                await self.queue.put((trace_id, collected))

    async def trace_processor(self, worker_id=0):
        while True:
            trace_id, messages = await self.queue.get()
            print(f"[Worker {worker_id}] Got trace {trace_id}")
            await process_trace(trace_id, messages)
            self.queue.task_done()

async def main():
    collector = TraceCollector()
    redis = await aioredis.create_redis('redis://localhost')

    # Start multiple background processors
    for i in range(NUM_WORKERS):
        asyncio.create_task(collector.trace_processor(worker_id=i))

    # Subscribe to channel
    channels = await redis.subscribe('traces')
    ch1 = channels[0]

    print("Listening on Redis channel: traces ...")

    while await ch1.wait_message():
        raw_msg = await ch1.get_json()
        await collector.message_handler(raw_msg)

if __name__ == "__main__":
    asyncio.run(main())
